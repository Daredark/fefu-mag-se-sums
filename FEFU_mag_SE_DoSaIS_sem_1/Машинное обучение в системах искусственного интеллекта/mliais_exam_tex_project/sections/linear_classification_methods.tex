\section{Линейные методы классификации}

\subsection{Общая на всю пару картинка доски}

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

\subsection{2. План лекции}

Градиентные методы обучения
- Минимизация эмпирического риска
- Линейный классификатор
- Метод стохастического градиента SG - Stochastic Gradient

\subsection{3. Задачи построения разделяющей поверхности}

Гиперплоскость - разделяющая поверхность.

- Задача классификации с двумя классами, $Y = {\lbrace -1, +1 \rbrace}$:\
по обучающей выборке $X^l = {\left( x_i, y_i \right)}^l_{i=1}$ построить
алгоритм классификации
$a{\left( x, w \right)} = \text{sign}{f{\left( x, w \right)}}$, где:
    - $f{\left( x, w \right)}$ - \textit{разделяющая (дискриминантная) функция},
    - $w$ - вектор параметров.
- $f{\left( x, w \right)} = 0$ - разделяющая поверхность;
```хотим, чтобы классификатор был основан на принципе разделения```\
$M_i{\left( w \right)} = y_i f{\left( x_i, w \right)}$ - \textit{отступ} (margin)
объекта $x_i$; ```от поверхности```\
$M_i{\left( w \right)} < 0 \iff$ алгоритм
$a{\left( x, w \right)}$ ошибается на $x_i$.

- $x$ - признаковое описание объекта,
- $w$ - вектор параметров.

Если функция $f$ возвратила на объекте $x_i$:
- значение $> 0$, то относим $x_i$ в класс $+1$,
- значение $< 0$, то относим $x_i$ в класс $-1$,
- значение $= 0$, то относим $x_i$, например, в класс $+1$

Преимущество таких классификаторов: вводится понятие
\textit{"надежность классификации"}, которое связано с тем, насколько далеко объект
находится от границы между классами (если объект лежит близко к границе, то
небольшое изменение в условиях задачи способно менять его классовую
принадлежность).

- Если $y$ и $f$ \textbf{одного знака}, то \textbf{ошибки нет}:
    - чем больше абсолютное значение величины $M_i{(w)}$, тем надежнее
    классификация;
- Если $y$ и $f$ \textbf{разных знаков}, то \textbf{ошибка}:
    - если большое абсолютное значение $M_i{(w)}$, то это однозначно выброс.

\subsection{4. Задачи построения разделяющей поверхности}

```
понятие отступа позволяет записать функционал числа ошибок на обучающей
выборке (эмпирический риск)
```

- $f{\left( x, w \right)} = 0$ - разделяющая поверхность;\
$M_i{\left( w \right)} = y_i f{\left( x_i, w \right)}$ - \textit{отступ} (margin)
объекта $x_i$;\
$M_i{\left( w \right)} < 0 \iff$ алгоритм
$a{\left( x, w \right)}$ ошибается на $x_i$.
- \textit{Минимизация эмпирического риска}:

```
замена пороговой функции потерь на непрерывную
```

$$Q{(w)} = \sum_{i=1}^{l}{\left[ M_i{(w)} < 0 \right]} \quad \leqslant  \quad \widetilde{Q}{(w)} = \sum_{i=1}^{l}{\mathscr{L}{\left( M_i{(w)} \right)}} \rightarrow \min_w;$$

```
огрубление характеристики - ошибка или не ошибка - теряется информация о
надежности i-ого объекта
```

```
сделаем так, чтобы функционал непрерывным образом зависел бы от отступов
```

\textit{Функция потерь} $\mathscr{L}{(M)}$ невозрастающая, неотрицательная.

\textbf{Преимущества функции потерь} $\mathscr{L}{(M)}$:
1. более тонкая характеристика надежности классификации,
2. получаем инструмент, который позволит применять градиентные методы
оптимизации

Подбираем $\mathscr{L}{(M)}$ так, чтобы она сверху аппроксимировала
пороговую
функцию потерь, а т.к. $\mathscr{L}{(M)}$ мы минимизируем, то минимизируется
и исходный функционал;
если решать первую задачу, то это тяжелая задача комбинаторной оптимизации,
которая имеет бесконечно много решений.

\subsection{5. Непрерывные аппроксимации пороговой функции потерь}

Часто используемые непрерывные функции потерь $\mathscr{L}{(M)}$:

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|}
    \hline
        ~ & ~ \\ \hline
        \$V\{(M)\} = \{(1 - M)\}\_+\$ & кусочно-линейная (SVM) \\ \hline
        \$H\{(M)\} = \{(- M)\}\_+\$ & кусочно-линейная (Hebb's rule) \\ \hline
        \$L\{(M)\} = $\backslash$log\_2\{(1 + e\^\{-M\})\}\$ & логарифмическая (LR) \\ \hline
        \$Q\{(M)\} = \{(1 - M)\}\^2\$ & квадратичная (FLD) \\ \hline
        \$S\{(M)\} = 2\{(1 + e\^\{M\})\}\^\{-1\}\$ & сигмоидная (ANN) \\ \hline
        \$E\{(M)\} = e\^\{-M\}\$ & экспоненциальная (AdaBoost) \\ \hline
        \$\{$\backslash$left[ M < 0 $\backslash$right]\}\$ & пороговая функция потерь \\ \hline
    \end{tabular}
\end{table}

Градиентные методы - численные методы решения с помощью градиента задач,
сводящихся к нахождению экстремумов функции.

Градиент - это вектор, указывающий направление самого быстрого возрастания
функции.

\textbf{Современный принцип}: можно как угодно менять функции потерь и получать
тот или иной по качеству метод, потому что решение сильно зависит от
$\mathscr{L}{(M)}$ - зависит от того, как мы штрафуем за ошибки.

\subsection{6. Линейный классификатор}

$f_j \! : \; X \rightarrow \mathbb{R}, \; j = 1, \ldots, n$ - числовые признаки.

Возьмем вместно непонятной дискриминантной функции $f$ линейную функцию.

Будем считать, что объекты заданы векторами из $\mathbb{R}^n$, т.е. имеется $n$
числовых признаков $f_1, \ldots, f_n$ и мы состваляем их линейную
комбинацию с весами $w$.

$$a{(x, w)} = \text{sign}{\left( \sum_{j=1}^{n}{w_j f_j{(x)}} - w_0 \right)},$$

где $w_0, w_1, \ldots, w_n \in \mathbb{R}$ - коэффициенты (веса признаков);

Введем константный признак $f_0 \equiv -1$. ```технический прием для сокращения записи```

Векторная запись (нас интересует знак скалярного произведения $w$ на $x$):
$$a{(x, w)} = \text{sign}{\left( {\langle w, x\rangle} \right)}.$$

Отступы объектов $x_i$
($x$ и $w$ теперь находятся в пространстве $\mathbb{R}^{n+1}$):
$$M_i{(w)} = {\langle w, x_i \rangle} y_i.$$

\subsection{7. Похож ли нейрон на линейный классификатор?}

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

\subsection{8. Похож ли нейрон на линейный классификатор?}

\textbf{Нейрон} - это структурно-функциональная единица нервной системы,
представляющая собой электрически возбудимую клетку, которая обрабатывает и
передает информацию посредством электрических и химических сигналов.

\textbf{Аксон} - обычно длинный отросток нейрона, приспособленный для проведения
возбуждения и информации от тела нейрона к исполнительному органу или к
другим клеткам.

\textbf{Дендриты} - как правило, короткие и сильно разветвленные отростки
нейрона,
служащие главным местом образования влияющих на нейрон возбуждающих и
тормозных синапсов (разные нейроны имеют различное соотношение длины аксона
и дендритов), и которые передают возбуждение к телу нейрона.

\textit{Нейрон может иметь несколько дендритов и обычно только один аксон.
Один нейрон может иметь связи со многими (до 20 тысяч) другими нейронами.}

\subsection{9. Похож ли нейрон на линейный классификатор?}

\textbf{Синапс} - место контакта между двумя нейронами или между нейроном и
получающей сигнал эффекторной клеткой.
Служит для передачи нервного импульса между двумя клетками, причем в ходе
синаптической передачи амплитуда и частота сигнала могут регулироваться.

В синапсах начинает концентрироваться отрицательный заряд, который затем
переходит внутрь (ядра) клетки, и там, как только происходит концентрация
слишком большого отрицательного заряда, который пришел отовсюду (ото всех
её синапсов), клетка генерирует электрический импульс, который бежит по
аксону до конца, и так порождается "волна возбуждения";
если к той клетке, куда пришел импульс, также придут импульсы от других
клеток, она тоже возбудится и волна продолжится.

\subsection{10. Похож ли нейрон на линейный классификатор?}

Имеется некоторая аналогия с линейным классификатором:
\textit{величина заряда}, который проходит в клетку через синапсы - это \textit{признаки}
$f$, синоптические связи - это веса $w$, а коэффициент $w_0$ - это тот
порог, который необходим для того, чтобы началась генерация импульса.

Линейный классификатор - это, пусть и грубая, но модель нервной клетки,
поэтому создавая композиции таких классификаторов, есть надежда
конструировать обучающиеся системы, которые обучаются также как человек
(хотя видов нервных клеток позже было открыто много)

\subsection{11. Математическая модель нейрона}

Линейная модель нейрона МакКаллока-Питтса \[1943\]:

$$a{\left( x, w \right)} = \sigma{\left( {\langle w, x \rangle} \right)} = \sigma{\left( \sum_{j=1}^{n}{w_j f_j{\left( x \right)}} - w_0 \right)},$$

где $\sigma{\left( s \right)}$ - функция активации
(в частности, $\text{sign}$).

В 1940-1950 годы проводилось большое число нейрофизиологических
экспериментов в попытке понять, как происходит обучение в нервной клекте.

\textbf{Основной вывод}: запоминают синоптические связи, т.е. если две клетки
последовательно возбудились, то первая правильно предугадала тот ответ,
который генерирует следующая, за это синоптическая связь награждается
усилением - $w$ становится больше.

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Сумматор - функция, преобразующая выход в $-1$ и $+1$.

Эти механизмы были открыты сначала в нейрофизиологии, а потом математики
усмотрели в них градиентную оптимизацию некоторого функционала качества.

\subsection{14. Алгоритм SG (Stochastic Gradient)}

Стохастический - умеющий угадывать, случайный.

\textbf{Вход:}
- выборка $X^l$;
- темп обучения $\eta$ (или "градиентный шаг");
- параметр $\lambda$ (сколько предыдущих объектов будет запомнено,
темп забывания):
    - $\lambda$ можно назначить $1/k$, где $k$ - это количество
    усредняемых потерь $\varepsilon_i$.

\textbf{Выход:}
- веса $w_0, w_1, \ldots, w_n$.

1. инициализировать веса $w_j, \; j = 0, \ldots, n$:
    - будет отдельный слайд на тему эвристик;
2. инициализировать текущую оценку функционала:\
$Q \coloneqq \sum_{i=1}^{l}{\mathscr{L}{\left( {\langle w, x_i \rangle} y_i \right)}}$:
    - текущая оценка нужна для учета средних потерь классификатора на
    выборке;
3. \textbf{повторять}
4. выбрать объект $x_i$ из $X^l$ (например случайно):
    - не всегда;
5. вычислить потерю:
$\varepsilon_{i} \coloneqq \mathscr{L}{\left( {\langle w, x_i \rangle} y_i \right)}$;
    - пропустили выбранный объект через классификатор;
6. градиентный шаг:
$w \coloneqq w - \eta \mathscr{L}'{\left( {\langle w, x_i \rangle} y_i \right)} x_i y_i$:
    - примеряем формулу для выбранного объекта;
7. оценить значение функционала:
$Q \coloneqq {\left( 1 - \lambda \right)} Q + \lambda \varepsilon_i$;
    - способ грубо оценить $Q$, не пересчитывая его на всей выборке:
8. \textbf{пока} значение $Q$ и/или веса $w$ не стабилизируются:
    - стабилизация определяется \textbf{вручную}, когда значение $Q$ выходит на
    ровный участок, когда видно, что в течение ряда последних итераций
    значение $Q$ остается в неком диапазоне.

\subsection{1. Лекция 6. Линейные методы классификации, SVM}

\subsection{2. Задача обучения линейного классификатора}

\textbf{Дано:}
- Обучающая выборка $X^l = {(x_i, y_i)}^l_{i=1}$,
- $x_i$ - объекты, векторы из множества $X = \mathbb{R}^n$,
- $y_i$ - метки классов, элементы множества $Y = {\lbrace -1, +1\rbrace}$.

\textbf{Найти:}

Параметры $w \in \mathbb{R}^n, \;\; w_0 \in \mathbb{R}$ линейной модели классификации
$$a{(x; w, w_0)} = \text{sign}{\left( {\langle x, w \rangle} - w_0 \right)}.$$

\textbf{Критерий} - минимизация эмпирического риска:
$$\sum_{i=1}^{l}{\left[ a{(x_i; w, w_0)} \neq y_i \right]} = \sum_{i=1}^{l}{\left[ M_i{(w, w_0)} < 0 \right]} \rightarrow \min_{w, w_0},$$
где $M_i{(w, w_0)} = {\left( {\langle x_i, w \rangle} - w_0 \right)} y_i$ -
\textit{отступ} (margin) объекта $x_i$,

\textbf{Эмпирический риск} - среднее число ошибок на обучающей выборке.

\textbf{Отступ (margin)} - расстояние (со знаком) от объекта выборки до
разделяющей гиперплоскости.

- Если знак "+", то ошибки нет.
- Если знак "$-$", то ошибка есть.

\subsection{3. Аппроксимация и регуляризация эмпирического риска}

\textbf{Мультиколлениарность} - тесная корреляционная взаимосвязь между
отбираемыми для анализа признаками (совместно воздействующими на общий
результат), которая затрудняет оценивание параметров.

\textbf{Регуляризация} - метод добавления некоторой дополнительной информации к
условию, с целью решить некорректно поставленную задачу или предотвратить
переобучение.

\textbf{Регуляризация решает проблему мультиколлениарности, а также снижает
переобучение.}

\textbf{Вектор} $\mathbf{w}$ - это вектор нормали к разделяющей гиперплоскости.

\textbf{Скаляр} $\mathbf{w_0}$ - это сдвиг гиперплоскости относительно начала
координат.

\textbf{Норма (длина) вектора} $\mathbf{\Vert w \Vert}$ = корень из суммы
квадратов $w_i$.

\subsection{4. Аппроксимация и регуляризация эмпирического риска}

Эмпирический риск - это кусочно-постоянная функция.

Заменим его оценкой сверху, непрерывной по параметрам:
%$$
%\begin{split}
%Q{(w, w_0)} &= \sum_{i=1}^{l}{\left[ M_i{(w, w_0)} < 0 \right]} \leqslant\\
%&\leqslant \sum_{i=1}^{l}{\left( 1 - M_i{(w, w_0)} \right)}_{+} + \frac{1}{2C} {\Vert w \Vert}^2 \rightarrow \min_{w, w_0}.
%\end{split}
%$$

- \textit{Аппроксимация} штрафует объекты за приближение к границе классов,
увеличивая зазор между классами
- \textit{Регуляризация} штрафует неустойчивые решения в случае
мультиколлинеарности

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

На рисунке значение потерь - это невозврастающая функция от отступов.

Штрафуются все отрицательные отступы и объекты, лежащие на разделяющей
гиперплоскости - для поиска самого устойчивого решения.

\subsection{5. Оптимальная разделяющая гиперплоскость}

Линейный классификатор:
$a{(x, w)} = \text{sign}{\left( {\langle w, x \rangle} - w_0 \right)}$

Пусть выборка $X^l = {(x_i, y_i)}^l_{i=1}$ линейно разделима:
$$\exists w, w_0 : \quad M_i{(w, w_0)} = y_i{\left( {\langle w, x_i \rangle} - w_0 \right)} > 0, \quad i = 1, \ldots, l$$

Нормировка: $\displaystyle \min_{i=1,\ldots,l}{M_i{(w, w_0)}} = 1$

Разделяющая полоса (разделяющая гиперплоскость посередине):

%$$
%\begin{split}
%&{\lbrace x: \; -1 \leqslant {\langle w, x \rangle} - w_0 \leqslant 1 \rbrace}\\
%&\exists x_+ : \quad {\langle w, x_+ \rangle} - w_0 = +1\\
%&\exists x_- : \quad {\langle w, x_- \rangle} - w_0 = -1
%\end{split}
%$$

Ширина полосы:
$$\frac{\langle x_+ - x_-, w \rangle}{\Vert w \Vert} = \frac{2}{\Vert w \Vert} \rightarrow \max$$

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Для нормировки сделаем минимальное значение отступа равным 1.
Тогда этот минимум будет достигается на хотя бы двух объектах.

Задача максимизировать ширину полосы, т.е. $w$ нужно минимизировать по
норме:
$${\Vert w \Vert} \rightarrow \min.$$

\subsection{7. Влияние константы C на решение SVM}

SVM - аппроксимация и регуляризация эмпирического риска:
$$\sum_{i=1}^{l}{\left( 1 - M_i{(w, w_0)} \right)}_{+} + \frac{1}{2C} {\Vert w \Vert}^2 \rightarrow \min_{w, w_0}.$$

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Константа $C$ - это гиперпараметр регуляризации, который необходимо
подбирать вручную.

От константы $C$ зависит геометрия получаемого решения:
- большое $C$ - сужение ширины, но меньше ошибок;
- малое $C$ - расширение полосы, но больше ошибок.

\subsection{8. Классификация с различными ядрами}

Гиперплоскость в спрямляющем пространстве соответствует нелинейной
разделяющей поверхности в исходном.

Примеры с различными ядрами $K{(x, x')}$

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Линейный классификатор (с оптимальной разделяющей поверхностью)
преобразовывается в нелинейный (с такой же поверхностью).

Спрямляющее пространство - это пространство большей размерности, при
переходе в которое выборка становится разделимой.

\subsection{9. Плюсы метода SVM}

- хорошо работает с пространством признаков большого размера;
- хорошо работает с данными небольшого объема;
- алгоритм максимизирует разделяющую полосу, которая, как подушка
безопасности, позволяет уменьшить количество ошибок классификации;
- алгоритм сводится к решению задачи квадратичного программирования в
выпуклой области, то такая задача всегда имеет единственное решение
(разделяющая гиперплоскость с определенными гиперпараметрами алгоритма
всегда одна).

\subsection{10. Минусы метода SVM}

- долгое время обучения (для больших наборов данных);
- неустойчивость к шуму - выбросы в обучающих данных становятся опорными
объектами-нарушителями и напрямую влияют на построение разделяющей
гиперплоскости;
- не описаны общие методы построения ядер и спрямляющих пространств,
наиболее подходящих для конкретной задачи в случае линейной неразделимости
классов;
- приходтся подбирать константу $C$ при помощи кросс-валидации.