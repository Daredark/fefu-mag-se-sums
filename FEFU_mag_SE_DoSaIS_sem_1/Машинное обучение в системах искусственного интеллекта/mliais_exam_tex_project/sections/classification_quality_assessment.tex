\section{Дополнительная информация}

- Рассказать на пальцах (настолько просто, насколько возможно, ёмко и основу).
- Если можешь объяснить на пальцах, тогда формулу можно не знать. Если не можешь объяснить на пальцах, вызубри (и пойми) формулу.
- На пальцах и понимаешь, как устроено - это пятерка.
- Четверка - это умение пользоваться.
- Тройка - это... хрен его знает, как это работает.
- Те, кто знает хорошо, получают особо сложные вопросы.
- Нужно очевидно отделать, что ответил на каждый вопрос (например, "с первым вопросом у меня всё!").
- Все вопросы и допы - на 10 минут (на 12 минут максимум).
- Одна пара - на первой неделе (на зачетной неделе пары, скорее всего, не будет, но не факт).
- Цель курса - научиться решать задачи кластеризации и классификации методами машинного обучения.

\section{1. Лекция. Оценка качества классификации}

\subsection{2. Содержание}

Оценка качества классификации:
- доля правильных классификаций;
- чувствительность и специфичность;
- точность (precision) и полнота (recall);
- площадь под кривой ROC (AUROC);
- площать под кривой Precision-Recall (AUPRC).

\subsection{3. Анализ ошибок классификации}

Задача классификации на два класса, $y_i \in {\lbrace -1, +1 \rbrace}$.

Алгоритм классификации $a{(x_i)} \in {\lbrace -1, +1 \rbrace}$

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
        ~ & ответ классификатора & правильный ответ \\ \hline
        TP, True Positive & \$a\{(x\_i)\} = +1\$ & \$y\_i = +1\$ \\ \hline
        TN, True Negative & \$a\{(x\_i)\} = -1\$ & \$y\_i = -1\$ \\ \hline
        FP, False Positive & \$a\{(x\_i)\} = +1\$ & \$y\_i = -1\$ \\ \hline
        FN, False Negative & \$a\{(x\_i)\} = -1\$ & \$y\_i = +1\$ \\ \hline
    \end{tabular}
\end{table}

\textit{Доля правильных классификаций (чем больше, тем лучше):}
$$\text{Accuracy} = \frac{1}{l} \sum_{i=1}^{l}{\left[ a{(x_i)} = y_i \right]} = \frac{\text{TP} + \text{TN}}{\text{FP} + \text{FN} + \text{TP} + \text{TN}}$$

\textbf{Недостаток:} не учитывается ни численность (дисбаланс) классов, ни цена
ошибки на объектах разных классов.

Positive и Negative - это ответы классификатора.

True и False - это правильность ответа.

Дисбаланс классов - это ситуация, когда экземпляров одного класса в выборке
существенно больше, чем экземпляров другого класса.

\subsection{4. Функции потерь, зависящие от штрафов за ошибку}

Задача классификации на два класса, $y_i \in {\lbrace -1, +1 \rbrace}$.\
Модель классификации: $a{(x; w, w_0)} = \text{sign}{\left( g{(x, w)} - w_0 \right)}$.\
Чем больше $w_0$, тем больше $x_i$ таких, что $a{(x_i)} = -1$.

Пусть $\lambda_y$ - штраф за ошибку на объекте класса $y$.\
Функция потерь теперь зависит от штрафов:$$\displaystyle \mathscr{L}{(a, y)} = \lambda_{y_i}{\left[ a{(x_i ; \: w, w_0) \neq y_i} \right]} = \lambda_{y_i}{\left[ {\left( g{(x_i, w)} - w_0 \right)} y_i < 0 \right]}.$$

> \textbf{Проблема}\
На практике штрафы ${\lbrace \lambda_y \rbrace}$ могут пересматриваться
> - Нужен удобный способ выбора $w_0$ в зависимости от ${\lbrace \lambda_y \rbrace}$, не требующий построения $w$ заново.
> - Нужна характеристика качества модели $g{(x, w)}$, не зависащая от
штрафов ${\lbrace \lambda_y \rbrace}$ и численности классов.

Потеря зависит от того, к какому классу на самом деле принадлежит объект.

Примеры разной цены ошибки: "свой-чужой" (зенитная установка на границе),
"хороший-плохой" (заемщик в банке).

Хотелось бы получить меру качества параметра $w$.

\subsection{5. Определение ROC-кривой}

Кривая ошибок ROC (receiver operating characteristic).\
Каждая точка кривой соответствует некоторому $a{(x; w, w_0)}$.
- по оси $X$: доля \textit{ошибочных положительных классификаций} (FPR - false positive rate):$$\text{FPR}{(a, X^l)} = \frac{\sum_{i=1}^{l}{\left[ y_i = -1 \right]}{\left[ a{(x_i; w, w_0)} = +1 \right]}}{\sum_{i=1}^{l}{\left[ y_i = -1 \right]}};$$
$1 - \text{FPR}{(a)}$ называется \textit{специфичностью} алгоритма $a$.
- по оси $Y$: доля \textit{правильных положительных классификаций} (TPR - true positive rate):$$\text{TPR}{(a, X^l)} = \frac{\sum_{i=1}^{l}{\left[ y_i = +1 \right]}{\left[ a{(x_i; w, w_0)} = +1 \right]}}{\sum_{i=1}^{l}{\left[ y_i = +1 \right]}};$$
$\text{TPR}{(a)}$ называется также \textit{чувствительностью} алгоритма $a$.

Решалась проблема "свой-чужой" для военных приемников сигнала, поэтому
такая терминология.

Чем выше специфичность алгоритма, тем лучше.

Чем выше чувствительность алгоритма, тем лучше.

\subsection{6. Пример ROC-кривой}

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Лучшие классификаторы находятся в левом верхнем углу, средние - ближе к
диагонали.

AUC - Area Under the Curve.

FPR и TPR - это относительные характеристики, нормированные на мощность
каждого класса.

\subsection{7. Алгоритм эффективного построения ROC-кривой}

> \textbf{Вход:} выборка $X^l$; дискриминантная функция $g{(x, w)}$;\
\textbf{Выход:} ${\lbrace {(\text{FPR}_i, \text{TPR}_i)} \rbrace}_{i=0}^{l}$, AUC - площадь под ROC-кривой.\
$l_y \coloneqq \sum_{i=1}^{l}{\left[ y_i = y \right]}$, для всех $y \in Y$;\
упорядочить выборку $X^l$ по убыванию значений $g{(x_i, w)}$;\
поставить первую точку в начало координат:\
${(\text{FPR}_0, \text{TPR}_0)} \coloneqq {(0, 0)}; \; \text{AUC} \coloneqq 0;$\
\textbf{для} $i \coloneqq 1, \ldots, l$
> - \textbf{если} $y_i = -1$ \textbf{то}
>   - $\text{FPR}_i \coloneqq \text{FPR}_{i-1} + \frac{1}{l_{-}}; \quad \text{TPR}_i \coloneqq \text{TPR}_{i - 1};$
>   - $\text{AUC} \coloneqq \text{AUC} + \frac{1}{l_{-}}\text{TPR}_i;$
> - \textbf{иначе}
>   - $\text{FPR}_i \coloneqq \text{FPR}_{i-1}; \quad \text{TPR}_i \coloneqq \text{TPR}_{i-1} + \frac{1}{l_{+}}$

Построение за один проход по выборке.

Площадь под ROC-кривой показывает, насколько хорошо построена модель
классификации (насколько хорошо подобран параметр $w$).

По ROC-кривой определяется точка, которая ближе всего к (0, 1) - выбирается
значение $w_0$.

\subsection{8. Оценки качества двухклассовой классификации}

В информационном поиске:
- Точность, $\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$ - доля релевантных среди найденных
- Полнота, $\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$ - доля найденных среди релевантных

В медицинской диагностике:
- Чувствительность, $\text{Sensitivity} = \frac{\text{TP}}{\text{TP} + \text{FN}}$ - доля верных положительных диагнозов
- Специфичность, $\text{Specificity} = \frac{\text{TN}}{\text{TN} + \text{FP}}$ - доля верных отрицательных диагнозов

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Мера качества AUC плохо работает в информационном поиске, когда ищется
небольшое число релевантной информации в большом объеме данных.

Важно найти то, что нужно (релевантные и при этом редкие объекты), но
также не найти в процессе много лишнего.

\subsection{9. Точность и полнота многоклассовой классификации}

Для каждого класса $y \in Y$:
- $\text{TP}_y$ - верные положительные
- $\text{FP}_y$ - ложные положительные
- $\text{FN}_y$ - ложные отрицательные

Точность и полнота с \textbf{мИкроусреднением}:
- Precision: $\displaystyle P = \frac{\sum_y{\text{TP}_y}}{\sum_y{(\text{TP}_y + \text{FP}_y)}}$;
- Recall: $\displaystyle R = \frac{\sum_y{\text{TP}_y}}{\sum_y{(\text{TP}_y + \text{FN}_y)}}$;

Микроусреднение НЕ чувствительно к ошибкам на малочисленных классах

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Если классов много и численность их разная, нужно определиться, что важнее
(чего должно быть больше): \textbf{классов}, которые определяются правильно, или
\textbf{объектов}, которые определяются правильно.

Когда много классов, отличаем один конкретный класс $y$ от всех остальных.

\subsection{10. Точность и полнота многоклассовой классификации}

Для каждого класса $y \in Y$:
- $\text{TP}_y$ - верные положительные
- $\text{FP}_y$ - ложные положительные
- $\text{FN}_y$ - ложные отрицательные

Точность и полнота с \textbf{мАкроусреднением}:
- Precision: $\displaystyle P = \frac{1}{\vert Y \vert} \sum_{y}{\frac{\text{TP}_y}{\text{TP}_y + \text{FP}_y}}$;
- Recall: $\displaystyle R = \frac{1}{\vert Y \vert} \sum_{y}{\frac{\text{TP}_y}{\text{TP}_y + \text{FN}_y}}$;

Макроусреднение чувствительно к ошибкам на малочисленных классах

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

В макроусреднение добавляется усреднение на классах.

Это нужно тогда, когда нужно чтобы алгоритм работал хорошо в независимости
от число классов (с учетом всех малочисленных) и для большинства этих
классов.

\subsection{11. Кривые ROC и Precision-Recall}

Модель классификации: $a{(x)} = \text{sign}{\left( {\langle x, w \rangle} - w_0 \right)}$

Каждая точка кривой соответствует значению порога $w_0$

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

- AUROC - площадь под ROC-кривой
- AUPRC - площадь под кривой Precision-Recall

На левом графике нужно стремиться в левый верхний угол.

На правом графике нужно стремиться в правый верхний угол (потому что и
точность, и полнота должны быть как можно больше).

При увеличении полноты, точность может увеличиваться или уменьшаться.

\subsection{12. Резюме по оценкам качества}

- Чувствительность и специфичность лучше подходят для задач с несбалансированными классами.
- Точность и полнота лучше подходят для задач поиска, когда доля объектов релевантного класса очень мала.
- AUROC лучше подходит для оценивания качества, когда соотношение цены
ошибок не фиксировано.
- AUPRC - площадь под кривой точность-полнота.

AUROC для одноклассовой классификации.

AUPRC для многоклассовой классификации.