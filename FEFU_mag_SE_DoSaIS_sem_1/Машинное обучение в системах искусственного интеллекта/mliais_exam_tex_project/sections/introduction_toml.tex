\section{Введение в машинное обучение, наверное???}

\subsection{1. Тема: Введение, цель, структура, понятия}

\subsection{2. Содержание}

1. Описание Курса, учебный план, литература.
2. Типы обучения, сценарии машинного обучения.
3. Обучения: с учителем / без учителя, специфика.
4. Приложения, смежные направления исследований.
5. Современная концепция анализа данных.
6. Этапы решения задач машинного обучения.

\subsection{2.1. Далее устная информация}

- Что такое искусственный интеллект?
- Какие задачи может решать искусственный интеллект, а какие человек?
- Какие задачи искусственный интеллект может уже решать?

Машинное обучение - это одно из направлений искусственного интеллекта.
МЛ - это два типа основных задач: \textbf{классификация} и \textbf{кластеризация}
\subsection{3. Описание курса}

\textbf{Цель курса} - рассмотрение постановок основных задач обучения по
прецедентам, изучение методов их решения, а также алгоритмов,
реализующих эти методы.

\textbf{Задачи курса}:

- Базовые понятия, типы и примеры прикладных задач.
- Классические. наиболее часто используемые методы.
- Современные приложения для машинного обучения.
- Практика по решению прикладных задач на Python.

Курс основан на лекциях К.В. Воронцова и материалах MachineLearning.ru

\subsection{3.1. Далее устная информация}

Чем алгоритм отличается от метода?
- метод не цикличен
- алгоритм - конечен
- метод - нечто большее
- алгоритм - нечто конкретное
- чемодан с инструментами - это метод, но внутри него инструменты -
алгоритмы (некий образ, чтобы было понимание)

\subsection{4. Теоретическая часть}

Понятия машинного обучения, которые мы изучим:
- индукция, дедукция
- обучение с учителем, обучение без учителя
- алгоритм обучения, решающее правило
- фунционал качества, эффективность
- ошибка, эмпирический риск
- скользящий контроль (кросс-проверка)
- переобучение
- обобщающая способность
- модельные, реальные данные
- модель зависимости, задачи обучения
- обучающая выборка, контрольная выборка
- объект, признак, класс, кластер


\subsection{4.1. Далее устная информация}


\textbf{Объект} - это объект нашего исследования, в каждой задаче он свой.

\textbf{Признак} - некоторое свойство объекта, и у этого свойства есть какие-то
значения свойств, которые похожи на значения свойств других объектов этого
класса.
Положим яблоко - это \textbf{класс}. Тогда \textbf{признак} - это цвет. У признака
есть своё множество - (красный, зеленый, желтый).

\textbf{Объект} - это что-то, что похоже на яблоко (например, апельсин).

У класса груши может быть свой признак цвета - множество, состоящее из
(зеленый, желтый).

Класс у объекта желтого цвета - может быть яблоко, может быть груша.

Если объект - красного цвета, то это не груша, а яблоко.

\subsection{5. Практическая часть}

1. Методы классификации:
    - Метрические методы классификации (5).
    - Логические методы классификации (3).
    - Линейные методы классификации (2).
    - Байесовские методы классификации (1).
2. Методы кластеризации (4).
3. Восстановление регрессии (2).
4. Ранжирование, временные ряды, ассоциативные правила, нейронные сети.

(Цифры сверху - количество алгоримтов, о которых будет рассказано)

\subsection{5.1. Далее устная информация}

Что такое классификация?

Объектам исследования мы должны сопоставить какой-то класс.


\subsection{7. Самостоятельная работа}

- Видеолекции Воронцова К.В. "Машинное обучение"
Школы анализа данных (ШАД) Яндекс.
- MachineLearning.ru - информационно-аналитический ресурс по машинному
обучению (курс Воронцова К.В.)
- Бринк Х., Ричардс Д., Феверолв М. Машинное обучение
(Real-World Machine Learning) - СПб.: Питер, 2017.
- UCI Machine Learning Repository
https://archive.ics.uci.edu/ml/index.php

\subsection{8. Идея обучения машин}

Владимир Вапник:

\textit{"Конечно, очень интересно знать, как учится человек. Однако совсем не
обязательно, что это лучший путь для построения искусственных
самообучающихся машин.
Замечено, что исследование полета птиц никак не пригодилось при
конструировании самолета".}

Мы не можем сказать, что на пути прямого моделирования мозга достигнуты
весьма значительные результаты.

Человечеству, по-видимому, ещё далеко до конструирования
универсального решателя интеллектуальных задач,
но конкретные сложные задачи мы можем научить решать компьютер уже сейчас.

\subsection{9. Типы обучения машин}

По аналогии с обучение людей мы может классифицировать типы обучения машин,
выделив следующие типы:
- \textbf{Дедуктивное}, или \textbf{аналитическое, обучение}. Имеются знания,
сформулированные экспертом и как-то формализованные.
Программа должна выводить из этих правил конкретные факты и новые правила.
- \textbf{Индуктивное обучение}. На основе эмпирических данных программа строит
общее правило. Эмпирические данные могут быть получены самой программой в
предыдущие сеансы ее работы или просто предъявлены ей.
- \textbf{Комбинированное обучение}, содержащее элементы как дедуктивного, так и
индуктивного обучения.

\subsection{10. Типы обучения машин}

Deductive (deductive approach: \textbf{testing} theory): theory -> hypotheses
-> data -> confirmation

Inductive (inductive approach: \textbf{building} theory) data -> patterns
data -> tentative hypotheses -> theory

\subsection{10.1. Далее устная информация}

Дедуктивное - от общего к частному.

Индуктивное - ???

Дедукция - выдвижение некой гипотезы.

\subsection{11. Типичный сценарий индуктивного обучения}

Имеются \textbf{объекты}, каждый из которых характеризуется некоторым набором
\textbf{признаков} (свойств, входов).

Каждому объекту приписана отдельная величина, называемая \textbf{классом}
(выходом).

Имеется \textbf{обучающая выборка} - конечное множество наблюдаемых объектов,
для каждого из которых известны значения всех его признаков, а также класс
(значение выхода).

Используя выборку, нужно построить \textbf{решающее правило}, которое для нового
объекта предсказывало бы его класс.

\textit{Т.е. по входам требуется научиться предсказывать выход.}

\subsection{12. Типичный сценарий индуктивного обучения}

Признаки (входы) и классы (выходы) бывают:
- \textit{количественные} (цена, температура) и
- \textit{качественные}, или \textit{номинальные}, (пол, название заболевания,
отсутствие/присутствие конкретного симптома и т.п.; признак, принимающий
только два значения, называется \textit{бинарным}).

Если выход \textit{количественный}, то восстанавливаемое решающее правило
называется \textbf{регрессией}, а сама задача -
\textbf{задачей восстановления регрессии}.

Если выход \textit{качественный}, то решающее правило называется
\textbf{классификатором}, а задача - \textbf{задачей классификации}, или
\textbf{задачей распознавания образов}.

\subsection{13. Обучение с учителем, обучение без учителя}

Восстановление регрессии и классификация - это примеры задач
\textbf{обучения с учителем}, так как для каждого объекта из обучающей выборки
извествен выход, и можно считать, что его указывает некий учитель.

В рамках индуктивного обучения рассматривают также
\textbf{обучение без учителя}, в котором для объектов обучающей выборки выходы
неизвестны. Здесь необходимо определить, как объекты связаны друг с
другом, например, выделить группы (кластеры) близких по своим свойствам
объктов.

\subsection{13.1. Далее устная информация}

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
        ~ & \$n\_1\$ & \$n\_2\$ & \$n\_3\$ & \$$\backslash$ldots\$ & \$n\_4\$ & \$k\$ \\ \hline
        \$O\_1\$ & k & 0.3 & ~ & ~ & ~ & я \\ \hline
        ... & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        \$O\_m\$ & W & 0.11 & ~ & ~ & ~ & а \\ \hline
    \end{tabular}
\end{table}

\subsection{14. Прохождение обучения}

Обучение может происходить:
- как \textbf{до работы} программы (например, для распознавания
лиц программа сначала учится, а затем работает на настоящих данных),
- так и \textbf{во время работы} программы (например, для фильтрации спама).

\subsection{15. Первые определения}

\textit{Артур Самуэль} (1959, работа "Исследование в области машинного обучения
на примере игры в шашки"):

\textit{Машинное обучение это процесс, в результате которого машина (компьютер)
способна показывать поведение, которое в нее не было явно заложено
(запрограммировано).}

\textit{Том Митчелл} (1997, книга "Machine Learning"):

\textit{Говорят, что компьютерная программа обучается на основе опыта $E$ по
отношению к некоторому классу задач $T$ и меры качества $P$, если
качество решения задач из $T$, измеренное на основе $P$, улучшается с
приобретением опыта $E$.}

\subsection{16. Определение как направление исследований}

\textbf{Машинное обучение} - подраздел искусственного интеллекта, изучающий
алгоритмы, способные к обобщению и обучению.

Находится на стыке математической статистики, методов оптимизации и
классических математических дисциплин, но имеет также и собственную
специфику - \textit{проблемы вычислительной эффективности и переобучения}.

Многие методы индуктивного обучения разрабатывались как альтернатива
классическим статистическим подходам. Они тесно связаны с извлечение
информации и \textbf{интеллектуальным анализом данных} (\textit{Data Mining}).

Наиболее теоретические разделы машинного обучения объединены в
\textbf{теорию вычислительного обучения} (Computational Learning Theory. COLT).

\subsection{17. Специфика машинного обучения}

\textbf{Проблема вычислительной эффективности}

\textit{Эффективность} - это продуктивность использования ресурсов в достижении
какой-либо цели.
\textit{Вычислительная сложность алгоритма} - это функция, определяющая зависимость
объема работы, выполняемой некоторым алгоритмом, от размера входных данных.

\textbf{Переобучение (переподгонка)}

Явление, когда алгоритм хорошо классифицирует объекты из обучающей выборки,
но отностительно плохо работает на объектах, не участвовавших в обучении
(на объектах из контрольной выборки).
Это связано с тем, что в процессе обучения в обучающей выборке
обнаруживаются некоторые случайные закономерности, которые отсутствуют в
генеральной совокупности.

\subsection{17.1. Далее устная информация}

Переобучение - это немного неправильный перевод Overfitting.

\subsection{18. Недообучение и переобучение}

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

\subsection{18.1. Далее устная информация}

Модель, в данном случае, это линия.

\subsection{19. Теория и практика}

\textbf{Машинное обучение} - не только математическая, но и практическая
инженерная дисциплина.

Чистая теория, как правило, не приводит сразу к методам и алгоритмам,
применимым на практике.
Чтобы заставить их хорошо работать, приходится изобретать дополнительные
эвристики, компенсирующие несоответствие сделанных в теории предположений
условиям реальных задач.

Практически ни одно исследование в машинном обучении не обходится без
эксперимента на модельных или реальных данных, подтверждающего
практическую работоспособность метода.

\subsection{19.1. Далее устная информация}

Задание:
- подучить Python;
- выбрать выборку откуда-то.

\subsection{20. Области применения машинного обучения}

1. Распознавание образов, звуков, речи.
2. Робототехника и компьютерное зрение.
3. Медицинская и техническая диагностика.
4. Анализ информации в интернете: поиск, реклама, спам, плагиат, модерация,
вбросы, популярность.
5. Военные приложения: мониторинг, прогноз.
6. Астрономия, геология, геофизика, экономика.
7. Перевод текстов, компьютерная лингвистика и обработка естественных
языков, рубрикация.
8. Маркетинговые исследования, кредитный скоринг, биржевой надзор,
обнаружение мошенничества.
9. Интеллектуальные игры.

\subsection{21. Примеры приложений машинного обучения}

Machine Learning Applications:
- Predictive policing
- Surveillance systems
- Facial recognition
- Autonomous ("self-driving") vehicles
- Advertising and business intelligence
- Personal assistants: Google Now, Microsoft Cortana, Apple Siri, etc.
- Filtering algorithms/news feeds
- Recommendation engines
- Optical character recognition
- Political campaigns

\subsection{22. Открытые вопросы}

1. Какое количество и какой информации необходимо для обучения?
2. Какие данные лучше выбирать для обучения и почему?
3. Какой алгоритм решает поставленную задачу наилучшим образом?
4. Как свести какую-либо из задач обучения к аппроксимации или
оптимизации некоторой функции?

\subsection{23. Data Science}

\subsection{23.1. Далее устная информация}

Data Science - наука о данных.

Data Science объединяет в себе такие направления, как:
- Statistics
- Pattern Recognition
- Neurocomputing
- Machine Learning
- AI
- Data Mining
- KDD
- Databases \& Data Processing
- Visualisations

\subsection{24. Эволюция направлений}

- Artificial Intelligence (1950's - 1980's)
    - Early artificial intelligence stirs excitement.
- Machine Learning (1980's - 2010's)
    - Machine learning begins to flourish.
- Deep Learning (2010's - nowadays)
    - Deep learning breakthroughs drive AI boom

\subsection{25. Соревнования по машинному обучению}

Площадки для соревнований по машинному обучению:
- Kaggle (рекомендация от Смагина): kaggle.com
- ML Boot Camp: mlbootcamp.ru
- Sberbank Data Science Contest: contest.sdsj.ru

\subsection{26. Современная концепция анализа данных}

1. Данные могут быть разнородными, неточными, неполными (т.е. содержать
пропуски), противоречивыми, косвенными, и при этом иметь гигантские объемы
(поэтому понимание данных в конкрентых приложениях требует значительных
интеллектуальных усилий).
2. Алгоритмы анализа данных могут обладать "элементами интеллекта",
в частности, способностью обучаться по прецедентам, то есть делать общие
выводы на основе частных наблюдений (разработка таких алгоритмов также
требует значительных интеллектуальных усилий).
3. Процессы переработки сырых данных в информацию, а информации - в знания,
требуют нетривиальной автоматизации.

\subsection{27-32. Пример. Метод ближайшего соседа}

На плоскости разбросаны точки двух цветов: красные и синие.
Координаты и цвет каждой из них нам известны...

Пусть новый объект принадлежит...

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Таким образом, у нас получаются две области: в одной велика вероятность
появления красных точек, а в другой - синих.

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

Далее попробуем немного изменить алгоритм, и ориентироваться на
нексколько (k) ближайших соседей.
Пускай k будет равно пяти.

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

В этом случае мы сможем отсечь потенциально шумовые объекты и получить более
ровную границу разделения классов.

\subsection{27-32. Далее устная информация}

Шум - это вид ошибки.

Метод ближайшего соседа - один из самых популярных методов машинного
обучения среди простых (работает только при очень большой выборке).

\subsection{33. Представление обучающей выборки}

\includegraphics[scale=0.3]{figures/samplefigure.jpg}

В общем случае в задачах машинного обучения рассматриваются точки в
многомерном пространстве, а не на плоскости.
Каждая координата - признак.

\subsection{34. Признаковое описание объектов обучающих и контрольных выборок}

- Фиксируется совокупность $n$ показателей, измеряемых у всех объектов.
- Если все $n$ показателей числовые, то признаковые описания представляют
собой числовые векторы размерности $n$.
Каждый элемент вектора признаков несет информацию о некотором свойстве
объекта.
- Объекты могут описываться временными рядами, сигналами, изображениями,
видеорядами, текстами, попарными отношениями сходства или интенсивности
взаимодействия.
Наиболее интересным случаем является тот, при котором описание объектов
имеет внутреннюю логическую структуру.
Такими объектами могут быть последовательности событий, иерархически
организованные сети, алгоритмические и программные схемы.

\subsection{35. Цикл решения задачи}

\includegraphics[scale=0.3]{figures/samplefigure.jpg}