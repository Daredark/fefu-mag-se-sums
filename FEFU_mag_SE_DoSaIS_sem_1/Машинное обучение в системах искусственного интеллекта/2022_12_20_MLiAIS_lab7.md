
___
___
___
## Информация о занятии
- __Дисциплина:__ Машинное обучение в системах искусственного интеллекта (MLiAIS)
- __Преподаватель:__ Смагин Сергей Владимирович
- __Тип занятия:__ Лабораторная работа №6
- __Формат занятия:__ Очно (ДВФУ, D???)
- __Дата и время занятия:__ 06.12.2022, вт (чет.), 16:50-18:20
___
___
___

&nbsp;

## Лабораторная работа - Лекция 9.

&nbsp;

### ___1. Лекция 9. Методы кластеризации и частичного обучения___

&nbsp;

### ___2. Содержание___

&nbsp;

Задачи кластеризации и частичного обучения:
- постановка задач, некорректность первой;
- критерии качества кластеризации.

Алгоритмы кластеризации:
- метод $K$-средних ($\textit{K} \text{-means}$);
- алгоритм DBSCAN;
- иерархические методы.

&nbsp;

### ___3. Постановка задачи кластеризации___

&nbsp;

__Дано:__
- $X$ - пространство объектов;
- $X^l = {\lbrace x_1, \ldots, x_l \rbrace}$ - обучающая выборка;
- $\rho \! : X \times X \rightarrow {\left[ 0, \infty \right)}$ - функция расстояния между объектами.

__Найти:__
- $Y$ - множество кластеров,
- $a \! : X \rightarrow Y$ - алгоритм кластеризации,
- такие, что:
    - каждый кластер состоит из близких объектов;
    - объекты разных кластеров существенно различны.

Это задача _обучения без учителя_ (unsupervised learning).

Дано конечное множество объектов обучающей выборки, для которых указаны
их парные расстояния (без меток классов).

Нужно научиться объединять такие объекты в кластеры (сгустки) по принципу
взаимной близости.

Внутрикластерное расстояние - малое, межкластерное - большое.

&nbsp;

### ___4. Некорректность задачи кластеризации___

&nbsp;

Решение задачи кластеризации принципиально неоднозначно:
- точной постановки задачи кластеризации нет;
- существует много критериев качества кластеризации;
- существует много эвристических методов кластеризации;
- число кластеров $\vert Y \vert$, как правило, неизвестно заранее;
- результат кластеризации сильно зависит от метрики $\rho$, выбор которой
также является эвристикой.

__Пример:__ сколько здесь кластеров?

![СЛАЙД 4 НЕ ОТОБРАЖАЕТСЯ]()

Иногда число кластеров задают директивно (из каких-то своих соображений
или условий задачи), при этом далеко не всегда удается понять, сколько
их на самом деле.

На слайде все ответы правильные, потому что результат зависит от того,
насколькор далекими друг от друга мы считаем кластеры.

&nbsp;

### ___5. Цели кластеризации___

&nbsp;

- __Упростить дальнейшую обработку данных__, разбить множество $X^l$ на
группы схожих объектов чтобы работать с каждой группой в отдельности
(задачи классификации, регрессии, прогнозирования).
- __Сократить объём хранимых данных__, оставив по одному представителю от
каждого кластера (задачи сжатия данных).
- __Выделить нетипичные объекты__, которые не подходят ни к одному их
кластеров (задачи одноклассовой классификации).
- __Построить иерархию множества объектов__, пример - классификация
животных и растений К.Линнея (задачи таксономии).

Несмотря на неоднозначность, задачи кластеризации часто используются на
практике.

Карл Линней - создатель единой системы классификации растительного и
животного миров, в которой были обобщены и упорядочены знания всего
предыдущего периода развития биологии.

&nbsp;

### ___6. Типы кластерных структур___

&nbsp;

- внутрикластерные расстояния, как правило, меньше межкластерных
- ленточные кластеры
- кластеры с центром

Ленточные кластеры нарушают принцип о минимуме

&nbsp;

### ___7. Типы кластерных структур___

&nbsp;

- кластеры могут соединяться перемычками
- класетры могут накладываться на разреженный фон из редко расположенных
объектов
- кластеры могут перекрываться

&nbsp;

### ___8. Типы кластерных структур___

&nbsp;

- кластеры могут образовываться не по сходству, а по иным типам
регулярностей
- кластеры могут вообще отсутствовать

&nbsp;

- Каждый клас

&nbsp;

### ___9. Проблема чувствительности к выборку метрики___

&nbsp;

Результат зависит от нормировки признаков:

![СЛАЙД 9 НЕ ОТОБРАЖАЕТСЯ]()

После изменения масштаба по оси $X$ выделись кластеры "высокие студенты"
и "все остальные".

Пунктиром на втором рисунке изображен исходный кластер $B$ из первого
рисунка.

Проблема чувствительности метрики - это не хорошо и не плохо, это свойство
задачи кластеризации.

&nbsp;

### ___10. Постановка задачи частичного обучения (SSL)___

&nbsp;

__Дано:__
множество объектов $X$, множество классов $Y$;
- $X^k$
- $U = {\lbrace  \rbrace}$

&nbsp;

### ___11. SSL не сводится к классификации___

&nbsp;

__Пример 1.__
плотность классов восстановленные:

![СЛАЙД 11 НЕ ОТОБРАЖАЕТСЯ]()

Слева приведена оценка плотности распределения классов байесовским
классификатором (по пяти объектам каждого класса).

Справа - по всем объектам, а размеченные объекты указывают на то, какому
классу принадлежит соответствующая плотность.

&nbsp;

### ___12. SSL не сводится к классификации___

&nbsp;

__Пример 2.__ Методы классификации не учитывают кластерную структуру
неразмеченных данных

![СЛАЙД 12 НЕ ОТОБРАЖАЕТСЯ]()

Задача "Два полумесяца".

Метод ближайших соседей и SVM плохо раюотают на таких ленточных кластерах
при условии, когда частично размечены самые дальние друг от друга объекты
обучающей выборки (см. квадрат и треугольник).

&nbsp;

### ___13. SSL также не сводится и к кластеризации___

&nbsp;

__Пример 3.__
Методы кластеризации не учитывают приоритетность разметки над кластерной
структурой.

![СЛАЙД 13 НЕ ОТОБРАЖАЕТСЯ]()

Нетривиальный контрпример.

При частичном обучении разметка (метки учителя) имеет приоритет над
кластерной структурой

&nbsp;

### ___14. Качество кластеризации в метрическом пространстве___

&nbsp;

Пусть известны только попарные расстояния между объектами.
- Среднее внутрикластерное расстояние:
$$\displaystyle F_0 = \frac{\sum_{i_j}{{\left[ a_i = a_j \right]} \rho}}{}$$

&nbsp;

### ___15.___

&nbsp;

### ___16. Метод K-средних (K-means) для кластеризации___

&nbsp;

Минимизация суммы квадратов внутрикластерных

&nbsp;

### ___17. Метод K-средних (K-means) для частичного обучения___

&nbsp;

__Модификация алгоритма Ллойда__ (при наличии размеченных объектов ${\lbrace x_1, \ldots, x_k \rbrace}$)

> __вход:__ $X^l, \; K = {\vert Y \vert}$;\
__выход:__ центры кластеров $\mu_{a}, \; a \in Y$;\


&nbsp;

### ___18. Примеры неудачной кластеризации K-means___

&nbsp;

Причина - неудачное начальное приближение или существенная негауссовость
кластеров

&nbsp;

### ___19. Алгоритм кластеризации DBSCAN___

&nbsp;

Объект $x \in U$, его $\varepsilon$-окрестность $U_{\varepsilon}{(x)} = {\lbrace u \in U \! : \rho{(x, u)} \leqslant \varepsilon \rbrace}$

Каждый объект может быть одного из трех типов:
- корневой: имеющий плотную окрестность, ${\vert U_{\varepsilon}{(x)} \geqslant m \vert}$
- граничный: не корневой, но в окрестности корневого
- шумовой (выброс): не корневой и не граничный

![СЛАЙД 19 НЕ ОТОБРАЖАЕТСЯ]()

DBSCAN - Density-Based Spatial Clustering of Applications with Noise.

Алгоритм подходит для кластеров произвольной формы.

Настраиваются два параметра:
- $\varepsilon$

&nbsp;

### ___20.___

&nbsp;

### ___21. Преимущества алгоритма DBSCAN___

&nbsp;

- быстрая кластеризация больших данных:
    - $O{l^2}$ в худшем случае,
    - $O{l \ln{l}}$

&nbsp;

### ___22. Агломеративная иерархическая кластеризация___

&nbsp;

Алгоритм иерархической кластеризации (Ланс, Уильямс, 1967): итеративный
пересчет расстояний $R_{UV}$ между кластерами $U$, $V$.

&nbsp;

### ___23. Агломеративная иерархическая кластеризация___

&nbsp;

Как определить расстояния $R{(W, S)}$ между кластерами $W = U \cup V \; \text{и} \; S$, зная расстояния $R{(U, S)}$, $R{(V, S)}, R{(U, V)}$?

Формула, обобщающая большинство разумных

&nbsp;

### ___24. Частные случаи формулы Ланса-Уильямса___

&nbsp;

1. __Расстояние ближнего:__
- $\displaystyle R_{WS}^{б} = \min_{w \in W, s \in S}$

&nbsp;

### ___25. Частные случаи формулы Ланса-Уильямса___

&nbsp;

4. __Расстояние между центрами:__
- $R_{WS}^{ц} = \rho^2 {\left( \right)}$

&nbsp;

### ___26. Визуализация кластерной структуры___

&nbsp;

1. __Расстояние ближнего соседа:__

![СЛАЙД 26 НЕ ОТОБРАЖАЕТСЯ]()

Дендрограмма показывает процесс объединения объектов в кластеры.

&nbsp;

### ___27. Визуализация кластерной структуры___

&nbsp;

2. __Расстояние дальнего соседа:__

![СЛАЙД 27 НЕ ОТОБРАЖАЕТСЯ]()

&nbsp;

___